---
title: About Me
description: 
---

I am a 3rd year PhD student at [UCSD CSE](https://cse.ucsd.edu/), working with [Hao Zhang](https://cseweb.ucsd.edu/~haozhang/) at the [Hao AI Lab](https://hao-ai-lab.github.io/). My research focuses on building efficient and scalable systems for LLMs â€” from **serving** and **training** to **reasoning & agents**.

## Research Interests

- **LLM Serving Systems** â€” Disaggregated inference, goodput optimization ([DistServe](https://hao-ai-lab.github.io/blogs/distserve/))
- **LLM Training Systems** â€” Disaggregated attention for long-context training ([DistCA](https://arxiv.org/abs/2504.19223))
- **LLM Reasoning & Agents** â€” Efficient serving of reasoning programs ([Dynasor/Certaindex](https://arxiv.org/abs/2412.20993))
- **Database Systems** â€” Data analytics platforms, query acceleration

## Active Projects

| Project | Area | Venue |
|---------|------|-------|
| [DistCA](https://arxiv.org/abs/2504.19223) | Disaggregated LLM training | MLSys'26 |
| [Dynasor/Certaindex](https://arxiv.org/abs/2412.20993) | LLM reasoning serving | NeurIPS'25 |
| [DistServe](https://hao-ai-lab.github.io/blogs/distserve/) | Disaggregated LLM inference | OSDI'24 |

## Experience

| When | Where | What |
|------|-------|------|
| 2023 â€“ present | **UCSD** | PhD student, CSE |
| Summer 2025 | **Snowflake** | Research intern |
| Summer 2024 | **Microsoft Research** | Intern, RiSE group |
| 2020 â€“ 2023 | **[DataChat](https://www.datachat.ai/)** | Technical Lead â€” built core backend, NLP pipeline, led team of 5-10 engineers |
| 2017 â€“ 2023 | **UW-Madison** | BS + MS in CS, advised by [Jignesh Patel](https://pages.cs.wisc.edu/~jignesh/) ([Database Group](https://twitter.com/wiscdb?lang=en)) |

During Madison I also explored astronomy ([Ka Ho Yuen](https://www.khyuen.info/)), biochemistry ([Senes Lab](https://seneslab.biochem.wisc.edu/)), and geoscience ([Yuhao Kang](http://www.kkyyhh96.site/)) â€” 6 amazing years! ðŸŽ“

## Talks

- **DistServe: Disaggregating Prefill and Decoding for Goodput-optimized LLM Serving**. [CUDA Mode](https://www.youtube.com/watch?v=tIPDwUepXcA&t=1338s)

## Side Projects
- Alice in the Wondertech. [blog](/posts/alice)